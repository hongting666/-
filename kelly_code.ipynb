{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN8eZmXt0nx+g61ea0YujmU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hongting666/-/blob/main/kelly_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSZy4x7rKiWT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "r\"\"\"\n",
        "Kelly Model · Institutional Edition (Fixed Parameters + Excel Report)\n",
        "--------------------------------------------------------------------\n",
        "Scope & Constraints\n",
        "1) Asset universe (strict list):\n",
        "   - Index futures/ETFs: US_SPX(ES=F/^GSPC/SPY), US_NASDAQ(NQ=F/^IXIC/QQQ), SPY, QQQ, FEZ, EWJ, FXI, GLD, SLV\n",
        "   - Large-cap US equities: AAPL, TSLA, MAR, BABA, FSLR, SBUX, PLTR, NVDA\n",
        "   - Hong Kong equities: 700HK(0700.HK/TCEHY), 27HK(0027.HK), 883HK(0883.HK/CEO)\n",
        "\n",
        "2) Data source: yfinance. To switch to Bloomberg in the future, only replace `load_prices_robust()`.\n",
        "\n",
        "3) Dashboard (exported as Excel sheets):\n",
        "   - Using the latest trading day as the anchor, look back 5/10/20 years to compute range highs/lows.\n",
        "   - Under from_low / from_high, when thresholds {2%, 5%, 8%} are triggered,\n",
        "     hold for EVENT_EVAL_HOLD_D days; report win rate / mean / variance / Kelly_raw.\n",
        "\n",
        "4) Trading / Weights sheets:\n",
        "   - Whether to open/add today and suggested weights (based on Kelly_raw, TopK normalization, and vol targeting).\n",
        "   - Rebalance schedule & performance for a given period (default: last year).\n",
        "   - Full-history rebalance schedule.\n",
        "\n",
        "5) Performance bar: CAGR ≥ 10% and R_over_MDD ≥ 3. MaxDD definition:\n",
        "   - For each trade, record the deepest drawdown from ENTRY price (simple %), booked on the exit day;\n",
        "     at the portfolio level, MaxDD is the minimum across all booked trades (usually negative).\n",
        "\n",
        "6) Stop-loss: Hard stop fixed at 1.5% (ENTRY_DD_STOP_PCT=0.015), computed as a simple % from entry.\n",
        "\n",
        "7) Output: One Excel file (default: kelly_institutional_report.xlsx).\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import math, warnings, re, sys, itertools, random\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ==== GPU dependency check (RAPIDS: CuPy / cuDF) ====\n",
        "try:\n",
        "    import cupy as cp\n",
        "    import cudf\n",
        "    assert cp.cuda.runtime.getDeviceCount() > 0, \"No NVIDIA GPU detected\"\n",
        "except Exception as e:\n",
        "    raise RuntimeError(\n",
        "        \"An NVIDIA GPU with CuPy/cuDF (RAPIDS) is required and must be available.\\nDetails: %s\" % e\n",
        "    )\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "\n",
        "# =========================\n",
        "# Fixed parameters (incl. 1.5% hard stop)\n",
        "# =========================\n",
        "PREFERRED_MODE = \"futures_first\"         # options: \"futures_first\" / \"etf_first\"\n",
        "ALLOW_FALLBACK_TO_ETF = True\n",
        "\n",
        "CANONICAL_SYMBOLS_CORE = [\n",
        "    \"US_SPX\",\"US_NASDAQ\",\n",
        "    \"SPY\",\"QQQ\",\"FEZ\",\"EWJ\",\"FXI\",\"GLD\",\"SLV\",\n",
        "]\n",
        "CANONICAL_SYMBOLS_FULL = CANONICAL_SYMBOLS_CORE + [\n",
        "    \"AAPL\",\"TSLA\",\"MAR\",\"BABA\",\"FSLR\",\"SBUX\",\"PLTR\",\"NVDA\",\n",
        "    \"700HK\",\"27HK\",\"883HK\",\n",
        "]\n",
        "\n",
        "START = \"2005-01-01\"\n",
        "END   = None\n",
        "TRADING_DAYS = 252\n",
        "MIN_ROWS_OK = 1000\n",
        "\n",
        "# ===== Strategy parameters =====\n",
        "TRADE_LAG_D = 1  # T0_OPEN (signal today, execute next day)\n",
        "LOOKBACK_YEARS = 5\n",
        "DEFAULT_BAND_THRESH = 0.06\n",
        "BAND_THRESH: Dict[str, float] = {\n",
        "    \"AAPL\":0.08,\"TSLA\":0.09,\"MAR\":0.08,\"BABA\":0.09,\"FSLR\":0.09,\"SBUX\":0.08,\"PLTR\":0.09,\"NVDA\":0.08,\n",
        "    \"0700.HK\":0.09,\"0027.HK\":0.09,\"0883.HK\":0.09,\n",
        "}\n",
        "\n",
        "EVENT_EVAL_HOLD_D = 20\n",
        "MIN_EVENTS = 30\n",
        "FACTOR_GATE_MODE = \"all\"\n",
        "FACTOR_MIN_EVENT_SHARPE = 0.35\n",
        "FACTOR_MIN_WINRATE      = 0.58\n",
        "FACTOR_MIN_KELLY_RAW    = 0.09\n",
        "\n",
        "LONG_TREND_FILTER_ON = True\n",
        "MA_LONG = 200\n",
        "MA_SLOPE_FILTER_ON = True\n",
        "MA_SLOPE_WIN = 20\n",
        "\n",
        "# Capital management (baseline)\n",
        "KELLY_FRACTION = 0.2\n",
        "KELLY_MIN_USED = 0.0\n",
        "CAP_PER_ASSET_LONG = 0.5\n",
        "TOPK_PER_DAY = 3\n",
        "\n",
        "# Stops / take-profit / time stop\n",
        "STOP_SIGMA = 1.8\n",
        "TAKE_SIGMA = 3.4\n",
        "TIME_STOP_D = 120\n",
        "\n",
        "# Hard stop (simple % from entry price)\n",
        "ENTRY_DD_STOP_ON = True\n",
        "ENTRY_DD_STOP_PCT = 0.015   # 1.5%\n",
        "\n",
        "# Portfolio vol targeting & risk controls\n",
        "TARGET_DAILY_VOL = 0.012\n",
        "VOL_TARGET_ON  = True\n",
        "VOL_REBAL_FREQ = \"W\"\n",
        "VOL_LOOKBACK_D = 120\n",
        "GROSS_LEV_MAX  = 1.0\n",
        "\n",
        "# Drawdown brake thresholds\n",
        "DRAWDOWN_BRAKE_ON = True\n",
        "BRAKE_WINDOW_D = 84\n",
        "BRAKE_THRESH   = 0.08\n",
        "BRAKE_SCALE    = 0.30\n",
        "\n",
        "COOLDOWN_SWEEP = [0]  # fixed cooldown=0 (baseline)\n",
        "\n",
        "# Costs (baseline assumptions; tweak per market if needed)\n",
        "GLOBAL_DEFAULT = dict(SLIPPAGE_BPS=4.0, COMMISSION_BPS=1.0, STAMP_DUTY_BPS=0.0)\n",
        "COST_TABLE = {\n",
        "    \"ES=F\": dict(SLIPPAGE_BPS=3.0, COMMISSION_BPS=0.8),\n",
        "    \"NQ=F\": dict(SLIPPAGE_BPS=3.0, COMMISSION_BPS=0.8),\n",
        "    \"HSI=F\":dict(SLIPPAGE_BPS=6.0, COMMISSION_BPS=1.0),\n",
        "    \"NK=F\": dict(SLIPPAGE_BPS=4.0, COMMISSION_BPS=1.0),\n",
        "    \"SPY\": dict(SLIPPAGE_BPS=5.0, COMMISSION_BPS=1.2),\n",
        "    \"QQQ\": dict(SLIPPAGE_BPS=5.0, COMMISSION_BPS=1.2),\n",
        "    \"FEZ\": dict(SLIPPAGE_BPS=6.0, COMMISSION_BPS=1.5),\n",
        "    \"EWJ\": dict(SLIPPAGE_BPS=6.0, COMMISSION_BPS=1.5),\n",
        "    \"FXI\": dict(SLIPPAGE_BPS=7.0, COMMISSION_BPS=1.5),\n",
        "    \"GLD\": dict(SLIPPAGE_BPS=5.0, COMMISSION_BPS=1.2),\n",
        "    \"SLV\": dict(SLIPPAGE_BPS=6.0, COMMISSION_BPS=1.2),\n",
        "    \"AAPL\": dict(SLIPPAGE_BPS=8.0,  COMMISSION_BPS=1.2),\n",
        "    \"TSLA\": dict(SLIPPAGE_BPS=10.0, COMMISSION_BPS=1.2),\n",
        "    \"MAR\":  dict(SLIPPAGE_BPS=9.0,  COMMISSION_BPS=1.2),\n",
        "    \"BABA\": dict(SLIPPAGE_BPS=10.0, COMMISSION_BPS=1.2),\n",
        "    \"FSLR\": dict(SLIPPAGE_BPS=10.0, COMMISSION_BPS=1.5),\n",
        "    \"SBUX\": dict(SLIPPAGE_BPS=9.0,  COMMISSION_BPS=1.2),\n",
        "    \"PLTR\": dict(SLIPPAGE_BPS=11.0, COMMISSION_BPS=1.2),\n",
        "    \"NVDA\": dict(SLIPPAGE_BPS=8.0,  COMMISSION_BPS=1.2),\n",
        "    \"0700.HK\": dict(SLIPPAGE_BPS=12.0, COMMISSION_BPS=2.5, STAMP_DUTY_BPS=50.0),\n",
        "    \"0027.HK\": dict(SLIPPAGE_BPS=14.0, COMMISSION_BPS=2.5, STAMP_DUTY_BPS=50.0),\n",
        "    \"0883.HK\": dict(SLIPPAGE_BPS=14.0, COMMISSION_BPS=2.5, STAMP_DUTY_BPS=50.0),\n",
        "}\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED); cp.random.seed(SEED); random.seed(SEED)\n",
        "\n",
        "# =========================\n",
        "# 1) Data layer: symbol aliases, fallback download, and timezone handling\n",
        "# =========================\n",
        "ALIASES_FUTURES_FIRST: Dict[str, List[str]] = {\n",
        "    \"US_SPX\":     [\"ES=F\", \"^GSPC\", \"SPY\"],\n",
        "    \"US_NASDAQ\":  [\"NQ=F\", \"^IXIC\", \"QQQ\"],\n",
        "    \"HK_HSI\":     [\"HSI=F\", \"^HSI\", \"2800.HK\"],\n",
        "    \"JP_NIKKEI\":  [\"NK=F\", \"^N225\", \"EWJ\"],\n",
        "    \"JP_TOPIX\":   [\"^TOPX\", \"1306.T\", \"1550.T\", \"EWJ\"],\n",
        "    \"SPY\": [\"SPY\"], \"QQQ\": [\"QQQ\"], \"FEZ\": [\"FEZ\"], \"EWJ\": [\"EWJ\"],\n",
        "    \"FXI\": [\"FXI\"], \"GLD\": [\"GLD\"], \"SLV\": [\"SLV\"],\n",
        "    \"AAPL\":[\"AAPL\"], \"TSLA\":[\"TSLA\"], \"MAR\":[\"MAR\"], \"BABA\":[\"BABA\"],\n",
        "    \"FSLR\":[\"FSLR\"], \"SBUX\":[\"SBUX\"], \"PLTR\":[\"PLTR\"], \"NVDA\":[\"NVDA\"],\n",
        "    \"700HK\": [\"0700.HK\", \"TCEHY\"], \"27HK\":[\"0027.HK\"], \"883HK\":[\"0883.HK\",\"CEO\"],\n",
        "}\n",
        "ALIASES_ETF_FIRST: Dict[str, List[str]] = {\n",
        "    \"US_SPX\":     [\"^GSPC\", \"SPY\", \"ES=F\"],\n",
        "    \"US_NASDAQ\":  [\"^IXIC\", \"QQQ\", \"NQ=F\"],\n",
        "    \"HK_HSI\":     [\"^HSI\", \"2800.HK\", \"HSI=F\"],\n",
        "    \"JP_NIKKEI\":  [\"^N225\", \"EWJ\", \"NK=F\"],\n",
        "    \"JP_TOPIX\":   [\"^TOPX\", \"1306.T\", \"1550.T\"],\n",
        "    \"SPY\":[\"SPY\"],\"QQQ\":[\"QQQ\"],\"FEZ\":[\"FEZ\"],\"EWJ\":[\"EWJ\"],\"FXI\":[\"FXI\"],\"GLD\":[\"GLD\"],\"SLV\":[\"SLV\"],\n",
        "    \"AAPL\":[\"AAPL\"],\"TSLA\":[\"TSLA\"],\"MAR\":[\"MAR\"],\"BABA\":[\"BABA\"],\"FSLR\":[\"FSLR\"],\"SBUX\":[\"SBUX\"],\"PLTR\":[\"PLTR\"],\"NVDA\":[\"NVDA\"],\n",
        "    \"700HK\":[\"0700.HK\",\"TCEHY\"],\"27HK\":[\"0027.HK\"],\"883HK\":[\"0883.HK\",\"CEO\"],\n",
        "}\n",
        "\n",
        "_def_al = lambda: ALIASES_ETF_FIRST if PREFERRED_MODE == \"etf_first\" else ALIASES_FUTURES_FIRST\n",
        "\n",
        "def normalize_hk_usercode(sym: str) -> str:\n",
        "    \"\"\"Convert '700HK' to standard '0700.HK' format.\"\"\"\n",
        "    m = re.fullmatch(r\"(\\d{1,5})HK\", sym.upper())\n",
        "    if m: return f\"{m.group(1).zfill(4)}.HK\"\n",
        "    return sym\n",
        "\n",
        "def all_aliases_for(canonical: str) -> List[str]:\n",
        "    \"\"\"Given a canonical symbol, return the prioritized alias list (with fallbacks).\"\"\"\n",
        "    aliases_map = _def_al()\n",
        "    first = normalize_hk_usercode(canonical)\n",
        "    out, seen = [], set()\n",
        "    if first not in seen: seen.add(first); out.append(first)\n",
        "    if canonical in aliases_map:\n",
        "        for a in aliases_map[canonical]:\n",
        "            if not ALLOW_FALLBACK_TO_ETF and canonical in [\"HK_HSI\",\"JP_NIKKEI\",\"JP_TOPIX\",\"US_SPX\",\"US_NASDAQ\"]:\n",
        "                if \"=F\" not in a: continue\n",
        "            if a not in seen: seen.add(a); out.append(a)\n",
        "    if first in aliases_map:\n",
        "        for a in aliases_map[first]:\n",
        "            if not ALLOW_FALLBACK_TO_ETF and first in [\"HK_HSI\",\"JP_NIKKEI\",\"JP_TOPIX\",\"US_SPX\",\"US_NASDAQ\"]:\n",
        "                if \"=F\" not in a: continue\n",
        "            if a not in seen: seen.add(a); out.append(a)\n",
        "    return out\n",
        "\n",
        "def _try_download(sym: str, start: str, end: Optional[str]) -> Optional[pd.Series]:\n",
        "    \"\"\"Attempt to download adjusted close via yfinance (with timezone removal).\"\"\"\n",
        "    try:\n",
        "        df = yf.download(sym, start=start, end=end, auto_adjust=True, progress=False, threads=False)\n",
        "        if df is not None and not df.empty and \"Close\" in df:\n",
        "            s = df[\"Close\"].rename(sym)\n",
        "            if isinstance(s.index, pd.DatetimeIndex) and s.index.tz is not None:\n",
        "                s.index = s.index.tz_localize(None)\n",
        "            return s\n",
        "    except Exception as e:\n",
        "        print(f\"[warn] yf.download failed for {sym}: {e}\", file=sys.stderr)\n",
        "    try:\n",
        "        tk = yf.Ticker(sym)\n",
        "        hist = tk.history(start=start, end=end, auto_adjust=True)\n",
        "        if hist is not None and not hist.empty and \"Close\" in hist:\n",
        "            s = hist[\"Close\"].rename(sym)\n",
        "            if isinstance(s.index, pd.DatetimeIndex) and s.index.tz is not None:\n",
        "                s.index = s.index.tz_localize(None)\n",
        "            return s\n",
        "    except Exception as e:\n",
        "        print(f\"[warn] ticker.history failed for {sym}: {e}\", file=sys.stderr)\n",
        "    return None\n",
        "\n",
        "def fetch_one_symbol_with_fallback(canonical: str, start: str, end: Optional[str]):\n",
        "    \"\"\"Download with alias fallbacks until the minimum row threshold is met.\"\"\"\n",
        "    tried = []\n",
        "    for alias in all_aliases_for(canonical):\n",
        "        tried.append(alias)\n",
        "        s = _try_download(alias, start, end)\n",
        "        if s is None:\n",
        "            print(f\"[try] {canonical} → {alias} ... no data\", file=sys.stderr); continue\n",
        "        if len(s) < MIN_ROWS_OK:\n",
        "            print(f\"[try] {canonical} → {alias} ... too few rows ({len(s)}), keep trying\", file=sys.stderr); continue\n",
        "        print(f\"[ok] {canonical} → {alias} ({len(s)} rows)\")\n",
        "        return alias, s\n",
        "    print(f\"[fail] {canonical}: tried {tried}\", file=sys.stderr)\n",
        "    return None, None\n",
        "\n",
        "def ensure_tz_naive_index(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Ensure tz-naive DatetimeIndex.\"\"\"\n",
        "    if isinstance(df.index, pd.DatetimeIndex) and df.index.tz is not None:\n",
        "        new_df = df.copy(); new_df.index = new_df.index.tz_localize(None); return new_df\n",
        "    return df\n",
        "\n",
        "def load_prices_robust(canon_symbols: List[str], start: str, end: Optional[str]) -> Tuple[pd.DataFrame, Dict[str,str]]:\n",
        "    \"\"\"Batch load prices; return DataFrame and the alias map actually used.\"\"\"\n",
        "    frames = []; used_map: Dict[str,str] = {}\n",
        "    for c in canon_symbols:\n",
        "        alias, s = fetch_one_symbol_with_fallback(c, start, end)\n",
        "        if s is not None:\n",
        "            frames.append(s.to_frame()); used_map[c] = alias\n",
        "    if not frames:\n",
        "        raise RuntimeError(\"Failed to fetch data for all symbols. Check network connectivity and alias mapping.\")\n",
        "    prices = pd.concat(frames, axis=1).sort_index().ffill().dropna(how=\"all\")\n",
        "    prices = ensure_tz_naive_index(prices); prices.columns = [c.upper() for c in prices.columns]\n",
        "    return prices, used_map\n",
        "\n",
        "# =========================\n",
        "# 2) GPU utilities & event statistics\n",
        "# =========================\n",
        "def annualize_vol(daily_vol: float) -> float:\n",
        "    return daily_vol * math.sqrt(TRADING_DAYS)\n",
        "\n",
        "@dataclass\n",
        "class EventStats:\n",
        "    mean: float\n",
        "    var: float\n",
        "    winrate: float\n",
        "    sharpe: float\n",
        "    n: int\n",
        "\n",
        "def to_cupy_no_nulls(gser: cudf.Series, fill_value) -> cp.ndarray:\n",
        "    return gser.astype(\"float64\").fillna(fill_value).to_cupy()\n",
        "\n",
        "def _rolling_from_extrema_gser(gser: cudf.Series, years: int, mode: str, minp: int = 50) -> cudf.Series:\n",
        "    \"\"\"Distance to multi-year extrema: from_low or from_high.\"\"\"\n",
        "    win = years * TRADING_DAYS\n",
        "    if mode == \"from_low\":\n",
        "        trough = gser.rolling(window=win, min_periods=minp).min()\n",
        "        out = ((gser - trough) / trough).clip(lower=0)\n",
        "    elif mode == \"from_high\":\n",
        "        peak = gser.rolling(window=win, min_periods=minp).max()\n",
        "        out = ((peak - gser) / peak).clip(lower=0)\n",
        "    else:\n",
        "        raise ValueError(\"mode must be 'from_high' or 'from_low'\")\n",
        "    return out.fillna(0.0)\n",
        "\n",
        "def _event_stats_gpu(price_cp: cp.ndarray, trigger_mask_cp: cp.ndarray, hold_d: int=EVENT_EVAL_HOLD_D) -> EventStats:\n",
        "    \"\"\"Under the trigger mask, compute hold_d-day event returns (GPU).\"\"\"\n",
        "    T = int(price_cp.shape[0])\n",
        "    if T < hold_d + 2:\n",
        "        return EventStats(0.0, 0.0, 0.0, 0.0, 0)\n",
        "    ret = cp.empty(T, dtype=cp.float64); ret[0] = 0.0\n",
        "    ret[1:] = price_cp[1:] / price_cp[:-1] - 1.0\n",
        "    L = cp.log1p(ret)\n",
        "    prefix = cp.concatenate([cp.array([0.0], dtype=cp.float64), cp.cumsum(L)])\n",
        "    idx = cp.where(trigger_mask_cp.astype(cp.bool_))[0]\n",
        "    valid = idx[idx + hold_d < T]\n",
        "    if valid.size == 0:\n",
        "        return EventStats(0.0, 0.0, 0.0, 0.0, 0)\n",
        "    r = cp.exp(prefix[valid + hold_d + 1] - prefix[valid + 1]) - 1.0\n",
        "    mu  = float(cp.mean(r).get())\n",
        "    if r.size > 1:\n",
        "        var = float(cp.var(r, ddof=1).get()); std = float(cp.std(r, ddof=1).get())\n",
        "    else:\n",
        "        var = float((r[0]**2).get()); std = float(cp.abs(r[0]).get())\n",
        "    win = float((cp.mean((r > 0).astype(cp.float64))).get())\n",
        "    shp = 0.0 if std == 0 else (mu / std) * math.sqrt(TRADING_DAYS/hold_d)\n",
        "    return EventStats(mu, var, win, shp, int(valid.size))\n",
        "\n",
        "def kelly_from_stats(stats: EventStats) -> float:\n",
        "    if stats.var <= 1e-12 or math.isnan(stats.var): return 0.0\n",
        "    return float(stats.mean / stats.var)\n",
        "\n",
        "def choose_side_gpu(price_pd: pd.Series, years: int, thr: float) -> str:\n",
        "    \"\"\"Given a threshold, choose from_low/from_high based on historical stats.\"\"\"\n",
        "    gser = cudf.from_pandas(price_pd)\n",
        "    m_low  = _rolling_from_extrema_gser(gser, years, \"from_low\")\n",
        "    m_high = _rolling_from_extrema_gser(gser, years, \"from_high\")\n",
        "    price_cp = cp.asarray(price_pd.values, dtype=cp.float64)\n",
        "    trig_low_cp  = (to_cupy_no_nulls(m_low,  0.0) >= thr)\n",
        "    trig_high_cp = (to_cupy_no_nulls(m_high, 0.0) >= thr)\n",
        "    st_low  = _event_stats_gpu(price_cp, trig_low_cp)\n",
        "    st_high = _event_stats_gpu(price_cp, trig_high_cp)\n",
        "    return \"from_low\" if kelly_from_stats(st_low) >= kelly_from_stats(st_high) else \"from_high\"\n",
        "\n",
        "def factor_gate(stats: EventStats,\n",
        "                min_sharpe: float,\n",
        "                min_win: float,\n",
        "                min_kelly_raw: float,\n",
        "                mode: str=\"all\") -> bool:\n",
        "    \"\"\"Admission filter for event statistics.\"\"\"\n",
        "    conds = [\n",
        "        (stats.sharpe  >= min_sharpe),\n",
        "        (stats.winrate >= min_win),\n",
        "        (kelly_from_stats(stats) >= min_kelly_raw),\n",
        "    ]\n",
        "    return all(conds) if mode==\"all\" else any(conds)\n",
        "\n",
        "def rolling_std_cp(vec: cp.ndarray, win: int) -> cp.ndarray:\n",
        "    \"\"\"Rolling standard deviation on GPU (simplified).\"\"\"\n",
        "    n = vec.shape[0]\n",
        "    if n < win: return cp.full((n,), cp.nan, dtype=cp.float64)\n",
        "    wv = cp.lib.stride_tricks.sliding_window_view(vec, win)\n",
        "    stds = wv.std(axis=1, ddof=0)\n",
        "    pad = cp.full((win-1,), cp.nan, dtype=cp.float64)\n",
        "    return cp.concatenate([pad, stds])\n",
        "\n",
        "# =========================\n",
        "# 3) Backtest (fixed parameters)\n",
        "# =========================\n",
        "@dataclass\n",
        "class Position:\n",
        "    is_open: bool = False\n",
        "    entry_price: float = np.nan\n",
        "    entry_idx: int = -1\n",
        "    cooldown_left: int = 0\n",
        "    min_dd_since_entry: float = 0.0  # deepest drawdown (simple %) since entry\n",
        "\n",
        "def get_cost_for_symbol(symbol_alias: str) -> Dict[str, float]:\n",
        "    base = {**GLOBAL_DEFAULT}; base.update(COST_TABLE.get(symbol_alias, {}))\n",
        "    return dict(\n",
        "        SLIPPAGE_BPS=float(base.get(\"SLIPPAGE_BPS\", 0.0)),\n",
        "        COMMISSION_BPS=float(base.get(\"COMMISSION_BPS\", 0.0)),\n",
        "        STAMP_DUTY_BPS=float(base.get(\"STAMP_DUTY_BPS\", 0.0)),\n",
        "    )\n",
        "\n",
        "def tc_buy_effect_bps(symbol_alias: str) -> float:\n",
        "    c = get_cost_for_symbol(symbol_alias)\n",
        "    return c[\"SLIPPAGE_BPS\"] + c[\"COMMISSION_BPS\"]\n",
        "\n",
        "def tc_sell_effect_bps(symbol_alias: str) -> float:\n",
        "    c = get_cost_for_symbol(symbol_alias)\n",
        "    return c[\"SLIPPAGE_BPS\"] + c[\"COMMISSION_BPS\"] + c[\"STAMP_DUTY_BPS\"]\n",
        "\n",
        "def backtest_once(prices: pd.DataFrame,\n",
        "                  used_alias_map: Dict[str,str],\n",
        "                  cooldown_d: int = 0,\n",
        "                  default_band_thresh: float = DEFAULT_BAND_THRESH) -> Tuple[pd.Series, pd.DataFrame]:\n",
        "    tickers = list(prices.columns)\n",
        "    dates = prices.index\n",
        "    T, N = prices.shape\n",
        "\n",
        "    gpx = cudf.from_pandas(prices)\n",
        "    dd_or_up_np = np.zeros((T, N), dtype=np.float64)\n",
        "    ma_np       = np.full((T, N), np.nan, dtype=np.float64)\n",
        "    slope_ok_np = np.zeros((T, N), dtype=bool)\n",
        "    ev_stats: Dict[str, EventStats] = {}\n",
        "    gates_ok: Dict[str, bool] = {}\n",
        "\n",
        "    # Precompute side selection, trigger metric, and trend filters\n",
        "    for j, tk in enumerate(tickers):\n",
        "        thr = BAND_THRESH.get(tk, default_band_thresh)\n",
        "        side = choose_side_gpu(prices[tk], LOOKBACK_YEARS, thr)\n",
        "\n",
        "        metric_g = _rolling_from_extrema_gser(gpx[tk], LOOKBACK_YEARS, side)\n",
        "        dd_or_up_np[:, j] = cp.asnumpy(to_cupy_no_nulls(metric_g, 0.0))\n",
        "\n",
        "        ma_g = gpx[tk].rolling(window=MA_LONG, min_periods=MA_LONG//2).mean().fillna(np.nan)\n",
        "        ma_np[:, j] = cp.asnumpy(to_cupy_no_nulls(ma_g, np.nan))\n",
        "        slope_ok_np[:, j] = cp.asnumpy((ma_g.diff(MA_SLOPE_WIN) > 0).fillna(False).to_cupy()) if MA_SLOPE_FILTER_ON else True\n",
        "\n",
        "        price_cp = cp.asarray(prices[tk].values, dtype=cp.float64)\n",
        "        trig_cp  = (to_cupy_no_nulls(metric_g, 0.0) >= thr)\n",
        "        st = _event_stats_gpu(price_cp, trig_cp, hold_d=EVENT_EVAL_HOLD_D)\n",
        "        ev_stats[tk] = st\n",
        "        gates_ok[tk] = (st.n >= MIN_EVENTS) and factor_gate(\n",
        "            st, FACTOR_MIN_EVENT_SHARPE, FACTOR_MIN_WINRATE, FACTOR_MIN_KELLY_RAW, FACTOR_GATE_MODE\n",
        "        )\n",
        "\n",
        "    # Daily returns and vol\n",
        "    px_cp  = cp.asarray(prices.values, dtype=cp.float64)\n",
        "    rets_cp = cp.zeros((T, N), dtype=cp.float64)\n",
        "    rets_cp[1:, :] = px_cp[1:, :] / px_cp[:-1, :] - 1.0\n",
        "    cp.nan_to_num(rets_cp, copy=False, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "    rets_np = cp.asnumpy(rets_cp)\n",
        "\n",
        "    sigma20_np = np.empty((T, N), dtype=np.float64)\n",
        "    for j in range(N):\n",
        "        sigma20_np[:, j] = cp.asnumpy(rolling_std_cp(rets_cp[:, j], 20))\n",
        "\n",
        "    # Position states\n",
        "    pos = {tk: Position() for tk in tickers}\n",
        "    w_base_np = np.zeros((T, N), dtype=np.float64)\n",
        "    dd_close_cols = np.full((T, N), np.nan, dtype=np.float64)  # record the trade's deepest DD on exit day\n",
        "\n",
        "    for t in range(T):\n",
        "        # 1) Compute \"raw\" Kelly-based weight quota\n",
        "        k_used = np.zeros(N, dtype=np.float64)\n",
        "        for j, tk in enumerate(tickers):\n",
        "            thr = BAND_THRESH.get(tk, default_band_thresh)\n",
        "            trig_today = (dd_or_up_np[t, j] >= thr)\n",
        "            gate_ok = gates_ok[tk]\n",
        "            if LONG_TREND_FILTER_ON:\n",
        "                ma_v = ma_np[t, j]\n",
        "                trend_ok = (not np.isnan(ma_v)) and (prices.iloc[t, j] >= ma_v) and bool(slope_ok_np[t, j])\n",
        "            else:\n",
        "                trend_ok = True\n",
        "            if trig_today and gate_ok and trend_ok and pos[tk].cooldown_left == 0:\n",
        "                kr = kelly_from_stats(ev_stats[tk])\n",
        "                ku = max(KELLY_MIN_USED, min(kr*KELLY_FRACTION, CAP_PER_ASSET_LONG))\n",
        "            else:\n",
        "                ku = 0.0\n",
        "            k_used[j] = ku\n",
        "\n",
        "        # 2) Top-K normalization (cap number of names per day)\n",
        "        if TOPK_PER_DAY and TOPK_PER_DAY > 0:\n",
        "            idx_pos = np.where(k_used > 0)[0]\n",
        "            idx_sorted = idx_pos[np.argsort(k_used[idx_pos])[::-1]]\n",
        "            keep = idx_sorted[:TOPK_PER_DAY]\n",
        "        else:\n",
        "            keep = np.where(k_used > 0)[0]\n",
        "\n",
        "        total_k = k_used[keep].sum() if keep.size > 0 else 0.0\n",
        "        base_w = np.zeros(N, dtype=np.float64)\n",
        "        if total_k > 0: base_w[keep] = k_used[keep] / total_k\n",
        "\n",
        "        # 3) Check stops/take-profit/time-stop for open positions\n",
        "        for j, tk in enumerate(tickers):\n",
        "            if pos[tk].is_open:\n",
        "                start_loc = pos[tk].entry_idx\n",
        "                if (start_loc is None) or (not isinstance(start_loc, (int, np.integer))) or (start_loc < 0) or (start_loc >= t):\n",
        "                    pos[tk] = Position(is_open=False, cooldown_left=cooldown_d); continue\n",
        "                r_cum = (1.0 + rets_np[start_loc+1:t+1, j]).prod() - 1.0 if t > start_loc else 0.0\n",
        "                pos[tk].min_dd_since_entry = min(pos[tk].min_dd_since_entry, r_cum)\n",
        "                vol = sigma20_np[t, j]\n",
        "                stop_hit_sigma = (not np.isnan(vol)) and (vol > 0) and (r_cum <= -STOP_SIGMA * vol)\n",
        "                take_hit       = (not np.isnan(vol)) and (vol > 0) and (r_cum >=  TAKE_SIGMA * vol)\n",
        "                time_stop      = (TIME_STOP_D is not None) and ((t - start_loc) >= TIME_STOP_D)\n",
        "                stop_hit_entry = ENTRY_DD_STOP_ON and (r_cum <= -ENTRY_DD_STOP_PCT)\n",
        "                if stop_hit_entry or stop_hit_sigma or take_hit or time_stop:\n",
        "                    dd_close_cols[t, j] = pos[tk].min_dd_since_entry\n",
        "                    pos[tk] = Position(is_open=False, cooldown_left=cooldown_d)\n",
        "\n",
        "        # 4) Target weights (open/maintain)\n",
        "        tw = np.zeros(N, dtype=np.float64)\n",
        "        for j, tk in enumerate(tickers):\n",
        "            if pos[tk].cooldown_left > 0:\n",
        "                tw[j] = 0.0\n",
        "            else:\n",
        "                px_ = prices.iloc[t, j]\n",
        "                if (not pos[tk].is_open) and base_w[j] > 0 and (not np.isnan(px_)):\n",
        "                    pos[tk].is_open = True\n",
        "                    pos[tk].entry_price = px_\n",
        "                    pos[tk].entry_idx = t\n",
        "                    pos[tk].min_dd_since_entry = 0.0\n",
        "                    tw[j] = base_w[j]\n",
        "                elif pos[tk].is_open:\n",
        "                    tw[j] = base_w[j]\n",
        "                else:\n",
        "                    tw[j] = 0.0\n",
        "        w_base_np[t, :] = tw\n",
        "\n",
        "        # 5) Cooldown decrement\n",
        "        for tk in tickers:\n",
        "            if pos[tk].cooldown_left > 0:\n",
        "                pos[tk].cooldown_left -= 1\n",
        "\n",
        "    # Execution lag (T+1)\n",
        "    w_exec_np = np.vstack([np.zeros((TRADE_LAG_D, N)), w_base_np[:-TRADE_LAG_D, :]]) if TRADE_LAG_D > 0 else w_base_np.copy()\n",
        "\n",
        "    # ---- Portfolio NAV execution and transaction costs ----\n",
        "    nav_cp = cp.ones(T, dtype=cp.float64)\n",
        "    cur_w_cp = cp.zeros(N, dtype=cp.float64)\n",
        "\n",
        "    buy_bps  = np.array([tc_buy_effect_bps(used_alias_map.get(tk, tk)) for tk in tickers], dtype=np.float64)\n",
        "    sell_bps = np.array([tc_sell_effect_bps(used_alias_map.get(tk, tk)) for tk in tickers], dtype=np.float64)\n",
        "    buy_rt  = cp.asarray(-np.abs(buy_bps)/1e4, dtype=cp.float64)\n",
        "    sell_rt = cp.asarray(-np.abs(sell_bps)/1e4, dtype=cp.float64)\n",
        "\n",
        "    # Only rebalance on the specified frequency (default Fridays)\n",
        "    freq_mask = np.ones(T, dtype=bool) if VOL_REBAL_FREQ == \"D\" else (pd.to_datetime(dates).weekday == 4).astype(bool)\n",
        "\n",
        "    for i in range(T):\n",
        "        if i > 0:\n",
        "            day_ret = float((cur_w_cp @ rets_cp[i, :]).get())\n",
        "            nav_cp[i] = nav_cp[i-1] * (1.0 + day_ret)\n",
        "        if not freq_mask[i]:\n",
        "            continue\n",
        "\n",
        "        eff_target = TARGET_DAILY_VOL\n",
        "        if DRAWDOWN_BRAKE_ON:\n",
        "            start_win = max(0, i - BRAKE_WINDOW_D)\n",
        "            peak = float(cp.max(nav_cp[start_win:i+1]).get())\n",
        "            if peak > 0:\n",
        "                dd_now = float((nav_cp[i] / peak - 1.0).get())\n",
        "                if dd_now <= -BRAKE_THRESH:\n",
        "                    eff_target = TARGET_DAILY_VOL * BRAKE_SCALE\n",
        "\n",
        "        tgt_np = w_exec_np[i, :]\n",
        "        if tgt_np.sum() > 0:\n",
        "            start_cov = max(0, i - VOL_LOOKBACK_D)\n",
        "            window = rets_cp[start_cov:i+1, :]\n",
        "            window = cp.nan_to_num(window, copy=False, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "            if window.shape[0] >= 2:\n",
        "                cov = cp.cov(window, rowvar=False)\n",
        "                cur = cp.asarray(tgt_np, dtype=cp.float64)\n",
        "                port_sig = cp.sqrt(cur @ cov @ cur)\n",
        "                if float(port_sig.get()) > 0:\n",
        "                    cur = cur * (eff_target / port_sig)\n",
        "                gross = cp.sum(cp.abs(cur))\n",
        "                if float(gross.get()) > GROSS_LEV_MAX:\n",
        "                    cur = cur * (GROSS_LEV_MAX / gross)\n",
        "\n",
        "                if i > 0:\n",
        "                    delta = cur - cur_w_cp\n",
        "                    buy_turn  = cp.clip(delta, 0, None)\n",
        "                    sell_turn = cp.clip(-delta, 0, None)\n",
        "                    nav_cp[i] = nav_cp[i] * (1.0 + float((buy_turn @ buy_rt).get()) + float((sell_turn @ sell_rt).get()))\n",
        "                cur_w_cp = cur\n",
        "            else:\n",
        "                cur_w_cp = cp.asarray(tgt_np, dtype=cp.float64)\n",
        "        else:\n",
        "            if i > 0:\n",
        "                delta = -cur_w_cp\n",
        "                sell_turn = cp.clip(-delta, 0, None)\n",
        "                nav_cp[i] = nav_cp[i] * (1.0 + float((sell_turn @ sell_rt).get()))\n",
        "            cur_w_cp = cp.zeros(N, dtype=cp.float64)\n",
        "\n",
        "    nav_np = cp.asnumpy(nav_cp)\n",
        "    detail = pd.DataFrame(index=dates)\n",
        "    detail[\"NAV\"] = nav_np\n",
        "    for j, tk in enumerate(tickers):\n",
        "        detail[f\"W_base_{tk}\"] = w_base_np[:, j]\n",
        "        detail[f\"W_exec_{tk}\"] = w_exec_np[:, j]\n",
        "        detail[f\"DDclose_{tk}\"] = dd_close_cols[:, j]\n",
        "\n",
        "    return detail[\"NAV\"], detail\n",
        "\n",
        "# =========================\n",
        "# 4) Dashboard & utility functions\n",
        "# =========================\n",
        "def max_drawdown_from_entry_simple(detail: pd.DataFrame) -> float:\n",
        "    \"\"\"Portfolio-level minimum of per-trade drawdowns booked on exit day (simple % from entry).\"\"\"\n",
        "    cols = [c for c in detail.columns if c.startswith(\"DDclose_\")]\n",
        "    if not cols:\n",
        "        return 0.0\n",
        "    vals = pd.concat([detail[c] for c in cols], axis=0).dropna()\n",
        "    if vals.empty:\n",
        "        return 0.0\n",
        "    return float(vals.min())\n",
        "\n",
        "def extrema_high_low_table(prices: pd.DataFrame, lookbacks=(5,10,20)) -> pd.DataFrame:\n",
        "    \"\"\"Table of highs/lows over 5/10/20-year lookbacks.\"\"\"\n",
        "    rows = []\n",
        "    last = prices.index[-1]\n",
        "    for tk in prices.columns:\n",
        "        s = prices[tk].dropna()\n",
        "        rec = {\"Ticker\": tk}\n",
        "        for y in lookbacks:\n",
        "            start = last - pd.tseries.offsets.BDay(int(y*TRADING_DAYS))\n",
        "            s_win = s[s.index >= start]\n",
        "            if len(s_win) == 0:\n",
        "                rec.update({f\"Low_{y}Y\": np.nan, f\"LowDate_{y}Y\": np.nan,\n",
        "                            f\"High_{y}Y\": np.nan, f\"HighDate_{y}Y\": np.nan})\n",
        "            else:\n",
        "                lo = float(s_win.min()); hi = float(s_win.max())\n",
        "                lo_dt = s_win.idxmin(); hi_dt = s_win.idxmax()\n",
        "                rec.update({f\"Low_{y}Y\": round(lo, 4), f\"LowDate_{y}Y\": lo_dt.date(),\n",
        "                            f\"High_{y}Y\": round(hi,4), f\"HighDate_{y}Y\": hi_dt.date()})\n",
        "        rows.append(rec)\n",
        "    df = pd.DataFrame(rows)\n",
        "    cols = [\"Ticker\"]\n",
        "    for y in lookbacks:\n",
        "        cols += [f\"Low_{y}Y\", f\"LowDate_{y}Y\", f\"High_{y}Y\", f\"HighDate_{y}Y\"]\n",
        "    return df[cols]\n",
        "\n",
        "def conditional_event_table(prices: pd.DataFrame,\n",
        "                            thresholds=(0.02,0.05,0.08),\n",
        "                            lookbacks=(5,10,20),\n",
        "                            hold_d: int = EVENT_EVAL_HOLD_D) -> pd.DataFrame:\n",
        "    \"\"\"Conditional event stats table (from_low/from_high × threshold × holding period).\"\"\"\n",
        "    rows = []\n",
        "    gpx = cudf.from_pandas(prices)\n",
        "    for tk in prices.columns:\n",
        "        px_pd = prices[tk]\n",
        "        px_cp = cp.asarray(px_pd.values, dtype=cp.float64)\n",
        "        for lb in lookbacks:\n",
        "            for mode in (\"from_low\",\"from_high\"):\n",
        "                metric_g = _rolling_from_extrema_gser(gpx[tk], lb, mode)\n",
        "                for thr in thresholds:\n",
        "                    trig_cp  = (to_cupy_no_nulls(metric_g, 0.0) >= thr)\n",
        "                    st = _event_stats_gpu(px_cp, trig_cp, hold_d=hold_d)\n",
        "                    rows.append({\n",
        "                        \"Ticker\": tk, \"LookbackY\": lb, \"Mode\": mode, \"Threshold\": thr,\n",
        "                        \"WinRate\": round(st.winrate, 3),\n",
        "                        \"EventSharpe\": round(st.sharpe, 3),\n",
        "                        \"Mean\": round(st.mean, 6),\n",
        "                        \"Var\": round(st.var, 8),\n",
        "                        \"Kelly_raw\": round(kelly_from_stats(st), 4),\n",
        "                        \"N_events\": st.n\n",
        "                    })\n",
        "    df = pd.DataFrame(rows)\n",
        "    return df.sort_values([\"Ticker\",\"Mode\",\"LookbackY\",\"Threshold\"]).reset_index(drop=True)\n",
        "\n",
        "def today_signal_table(prices: pd.DataFrame,\n",
        "                       used_map: Dict[str,str],\n",
        "                       as_of: Optional[pd.Timestamp]=None,\n",
        "                       default_band_thresh: float = DEFAULT_BAND_THRESH) -> pd.DataFrame:\n",
        "    \"\"\"Today's signal table: triggers/gates, Kelly_raw, and suggested weights (after TopK).\"\"\"\n",
        "    if as_of is None:\n",
        "        as_of = prices.index[-1]\n",
        "    as_of = pd.to_datetime(as_of)\n",
        "    if as_of not in prices.index:\n",
        "        idx_asof = prices.index.searchsorted(as_of, side='right') - 1\n",
        "        idx_asof = max(0, min(idx_asof, len(prices.index)-1))\n",
        "        as_of = prices.index[idx_asof]\n",
        "\n",
        "    gpx = cudf.from_pandas(prices)\n",
        "    rows = []\n",
        "    k_used_map = {}\n",
        "\n",
        "    for tk in prices.columns:\n",
        "        thr = BAND_THRESH.get(tk, default_band_thresh)\n",
        "        side = choose_side_gpu(prices[tk], LOOKBACK_YEARS, thr)\n",
        "        metric_g = _rolling_from_extrema_gser(gpx[tk], LOOKBACK_YEARS, side)\n",
        "\n",
        "        # Align index\n",
        "        idx_m = metric_g.index.searchsorted(as_of, side='right') - 1\n",
        "        idx_m = max(0, min(int(idx_m), len(metric_g)-1))\n",
        "        dd_or_up = float(metric_g.iloc[idx_m])\n",
        "\n",
        "        # Event stats (gating + kelly_raw)\n",
        "        price_cp = cp.asarray(prices[tk].values, dtype=cp.float64)\n",
        "        trig_cp  = (to_cupy_no_nulls(metric_g, 0.0) >= thr)\n",
        "        st = _event_stats_gpu(price_cp, trig_cp, hold_d=EVENT_EVAL_HOLD_D)\n",
        "        gate_ok = (st.n >= MIN_EVENTS) and factor_gate(st, FACTOR_MIN_EVENT_SHARPE, FACTOR_MIN_WINRATE, FACTOR_MIN_KELLY_RAW, FACTOR_GATE_MODE)\n",
        "\n",
        "        # Trend filter\n",
        "        ma_g = gpx[tk].rolling(window=MA_LONG, min_periods=MA_LONG//2).mean().fillna(np.nan)\n",
        "        idx_ma = ma_g.index.searchsorted(as_of, side='right') - 1\n",
        "        idx_ma = max(0, min(int(idx_ma), len(ma_g)-1))\n",
        "        ma_val = float(ma_g.iloc[idx_ma])\n",
        "        price_today = float(prices.loc[as_of, tk])\n",
        "        slope_series = (ma_g.diff(MA_SLOPE_WIN) > 0).fillna(False)\n",
        "        slope_ok = bool(slope_series.iloc[idx_ma]) if MA_SLOPE_FILTER_ON else True\n",
        "        trend_ok = (not np.isnan(ma_val)) and (price_today >= ma_val) and slope_ok\n",
        "\n",
        "        trig_today = (dd_or_up >= thr)\n",
        "        kr = kelly_from_stats(st)\n",
        "        ku = max(KELLY_MIN_USED, min(kr*KELLY_FRACTION, CAP_PER_ASSET_LONG)) if (trig_today and gate_ok and trend_ok) else 0.0\n",
        "        k_used_map[tk] = ku\n",
        "\n",
        "        rows.append({\n",
        "            \"Ticker\": tk,\n",
        "            \"AliasUsed\": used_map.get(tk, tk),\n",
        "            \"Side\": side,\n",
        "            \"Trigger(>=th)\": round(dd_or_up, 4),\n",
        "            \"Threshold\": thr,\n",
        "            \"GateOK\": gate_ok,\n",
        "            \"TrendOK\": trend_ok,\n",
        "            \"Kelly_raw\": round(kr, 4),\n",
        "            \"k_used_raw\": round(ku, 4),\n",
        "        })\n",
        "\n",
        "    # TopK normalization → final suggested weights\n",
        "    arr = np.array([k_used_map[tk] for tk in prices.columns], dtype=float)\n",
        "    idx_pos = np.where(arr > 0)[0]\n",
        "    idx_sorted = idx_pos[np.argsort(arr[idx_pos])[::-1]]\n",
        "    keep = idx_sorted[:TOPK_PER_DAY]\n",
        "    final_w = np.zeros_like(arr)\n",
        "    if keep.size > 0:\n",
        "        s = arr[keep].sum()\n",
        "        if s > 0:\n",
        "            final_w[keep] = arr[keep] / s\n",
        "\n",
        "    # Write-back of weights and decision suggestions\n",
        "    for r in rows:\n",
        "        tk = r[\"Ticker\"]\n",
        "        w = float(final_w[list(prices.columns).index(tk)])\n",
        "        r[\"SuggestedWeight\"] = round(w, 4)\n",
        "        r[\"Decision\"] = (\"OPEN/ADD\" if w > 0 else \"STAY OUT\")\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "    df = df.sort_values([\"SuggestedWeight\",\"k_used_raw\"], ascending=[False, False]).reset_index(drop=True)\n",
        "    return df\n",
        "\n",
        "def evaluate_once(prices: pd.DataFrame, used_map: Dict[str,str], cooldown: int = 0,\n",
        "                  default_band_thresh: float = DEFAULT_BAND_THRESH) -> Tuple[pd.DataFrame, Dict[int, pd.DataFrame]]:\n",
        "    \"\"\"Full-history backtest (fixed parameters).\"\"\"\n",
        "    nav, det = backtest_once(prices, used_map, cooldown_d=cooldown, default_band_thresh=default_band_thresh)\n",
        "    total_ret = float(nav.iloc[-1] - 1)\n",
        "    daily_ret = nav.pct_change().fillna(0.0)\n",
        "    vol = float(daily_ret.std())\n",
        "    sharpe = (daily_ret.mean()/vol)*math.sqrt(TRADING_DAYS) if vol>0 else 0.0\n",
        "    mdd_simple = max_drawdown_from_entry_simple(det)\n",
        "    years = max(1e-9, len(nav)/TRADING_DAYS)\n",
        "    cagr = float(nav.iloc[-1])**(1/years) - 1\n",
        "    calmar = (cagr/abs(mdd_simple)) if mdd_simple < 0 else np.nan\n",
        "    R_over_MDD = (total_ret/abs(mdd_simple)) if mdd_simple != 0 else float('inf')\n",
        "\n",
        "    summ_row = {\n",
        "        \"CooldownD\": int(cooldown),\n",
        "        \"TotalReturn%\": round(total_ret*100, 2),\n",
        "        \"CAGR%\": round(cagr*100, 2),\n",
        "        \"Ann.Vol%\": round(annualize_vol(vol)*100, 2),\n",
        "        \"Sharpe\": round(sharpe, 3),\n",
        "        \"MaxDD%\": round(mdd_simple*100, 2),\n",
        "        \"R_over_MDD\": round(R_over_MDD, 2) if np.isfinite(R_over_MDD) else \"∞\",\n",
        "        \"Calmar\": round(calmar, 3) if not np.isnan(calmar) else np.nan\n",
        "    }\n",
        "    return pd.DataFrame([summ_row]), {int(cooldown): det}\n",
        "\n",
        "def summarize_period(nav: pd.Series, detail: pd.DataFrame,\n",
        "                     start_date: str, end_date: Optional[str]=None) -> Tuple[pd.DataFrame, pd.Series]:\n",
        "    \"\"\"Period summary (includes period MaxDD under this strategy's definition).\"\"\"\n",
        "    d0 = pd.to_datetime(start_date)\n",
        "    d1 = pd.to_datetime(end_date) if end_date is not None else nav.index[-1]\n",
        "    sub = nav[(nav.index >= d0) & (nav.index <= d1)]\n",
        "    if sub.empty:\n",
        "        raise ValueError(\"No data in the selected period.\")\n",
        "    nav0 = float(sub.iloc[0])\n",
        "    navN = sub / nav0\n",
        "    daily = navN.pct_change().fillna(0.0)\n",
        "    vol = float(daily.std())\n",
        "    years = max(1e-9, len(sub)/TRADING_DAYS)\n",
        "    cagr = float(navN.iloc[-1])**(1/years) - 1\n",
        "\n",
        "    # Use only exit records within the period to compute MaxDD\n",
        "    m = detail[(detail.index >= d0) & (detail.index <= d1)]\n",
        "    cols = [c for c in m.columns if c.startswith(\"DDclose_\")]\n",
        "    vals = pd.concat([m[c] for c in cols], axis=0).dropna()\n",
        "    mdd_simple = float(vals.min()) if not vals.empty else 0.0\n",
        "\n",
        "    total_ret = float(navN.iloc[-1] - 1)\n",
        "    sharpe = (daily.mean()/vol)*math.sqrt(TRADING_DAYS) if vol>0 else 0.0\n",
        "    calmar = (cagr/abs(mdd_simple)) if mdd_simple < 0 else np.nan\n",
        "    R_over_MDD = (total_ret/abs(mdd_simple)) if mdd_simple != 0 else float('inf')\n",
        "\n",
        "    summ = pd.DataFrame([{\n",
        "        \"Start\": d0.date(), \"End\": d1.date(),\n",
        "        \"TotalReturn%\": round(total_ret*100, 2),\n",
        "        \"CAGR%\": round(cagr*100, 2),\n",
        "        \"Ann.Vol%\": round(annualize_vol(vol)*100, 2),\n",
        "        \"Sharpe\": round(sharpe, 3),\n",
        "        \"MaxDD%\": round(mdd_simple*100, 2),\n",
        "        \"R_over_MDD\": round(R_over_MDD, 2) if np.isfinite(R_over_MDD) else \"∞\",\n",
        "        \"Calmar\": round(calmar, 3) if not np.isnan(calmar) else np.nan\n",
        "    }])\n",
        "    return summ, navN\n",
        "\n",
        "def build_trade_schedule(detail: pd.DataFrame,\n",
        "                         start_date: Optional[str]=None,\n",
        "                         end_date: Optional[str]=None,\n",
        "                         change_tol: float = 1e-4) -> pd.DataFrame:\n",
        "    \"\"\"Extract actual order-weight changes from W_exec_* columns to form a rebalance schedule.\"\"\"\n",
        "    df = detail.copy()\n",
        "    if start_date is not None:\n",
        "        df = df[df.index >= pd.to_datetime(start_date)]\n",
        "    if end_date is not None:\n",
        "        df = df[df.index <= pd.to_datetime(end_date)]\n",
        "\n",
        "    wcols = [c for c in df.columns if c.startswith(\"W_exec_\")]\n",
        "    tickers = [c.replace(\"W_exec_\", \"\") for c in wcols]\n",
        "    W = df[wcols].fillna(0.0)\n",
        "\n",
        "    # Identify rows with significant weight changes (including the first day)\n",
        "    changed = [0]\n",
        "    prev = W.iloc[0].values\n",
        "    for i in range(1, len(W)):\n",
        "        cur = W.iloc[i].values\n",
        "        if np.max(np.abs(cur - prev)) > change_tol:\n",
        "            changed.append(i)\n",
        "            prev = cur\n",
        "    out = df.iloc[changed][wcols].copy()\n",
        "    out.columns = tickers\n",
        "\n",
        "    # Attach natural-language actions (Open/Increase/Decrease/Close)\n",
        "    actions = []\n",
        "    prev = None\n",
        "    for _, row in out.iterrows():\n",
        "        cur = row.values\n",
        "        if prev is None:\n",
        "            prev = np.zeros_like(cur)\n",
        "        msgs = []\n",
        "        for j, tk in enumerate(tickers):\n",
        "            a, b = prev[j], cur[j]\n",
        "            if a < change_tol and b >= change_tol:\n",
        "                msgs.append(f\"{tk}: OPEN→{b:.2%}\")\n",
        "            elif a >= change_tol and b < change_tol:\n",
        "                msgs.append(f\"{tk}: CLOSE\")\n",
        "            elif abs(b - a) >= 1e-3:\n",
        "                msgs.append(f\"{tk}: {('ADD' if b>a else 'CUT')} {abs(b-a):.2%}\")\n",
        "        actions.append(\"; \".join(msgs))\n",
        "        prev = cur\n",
        "    out.insert(0, \"Actions\", actions)\n",
        "    out.index.name = \"Date\"\n",
        "    return out.reset_index()\n",
        "\n",
        "# =========================\n",
        "# 5) Report export (Institutional edition)\n",
        "# =========================\n",
        "def export_institutional_report(prices: pd.DataFrame, used_map: Dict[str,str],\n",
        "                                scenario_start: Optional[str] = None,\n",
        "                                scenario_end: Optional[str] = None,\n",
        "                                outfile: str = \"kelly_institutional_report.xlsx\"):\n",
        "    # 1) Full-history backtest (fixed cooldown=0)\n",
        "    summ_full, details_dict = evaluate_once(prices, used_map, cooldown=0, default_band_thresh=DEFAULT_BAND_THRESH)\n",
        "    det_full = details_dict[0]\n",
        "\n",
        "    # 2) Dashboard sheets\n",
        "    hilo = extrema_high_low_table(prices, lookbacks=(5,10,20))\n",
        "    prob = conditional_event_table(prices, thresholds=(0.02,0.05,0.08), lookbacks=(5,10,20), hold_d=EVENT_EVAL_HOLD_D)\n",
        "\n",
        "    # 3) Today's signals\n",
        "    today_tbl = today_signal_table(prices, used_map, as_of=None, default_band_thresh=DEFAULT_BAND_THRESH)\n",
        "\n",
        "    # 4) Scenario A: from scenario_start to latest (or scenario_end)\n",
        "    if scenario_start is None:\n",
        "        # Default to last one year: roll back 252 business days from the last trading date\n",
        "        last_dt = det_full.index[-1]\n",
        "        scenario_start = (last_dt - pd.tseries.offsets.BDay(TRADING_DAYS)).date().isoformat()\n",
        "\n",
        "    summ_a, nav_a = summarize_period(det_full[\"NAV\"], det_full, start_date=scenario_start, end_date=scenario_end)\n",
        "    sched_a = build_trade_schedule(det_full, start_date=scenario_start, end_date=scenario_end)\n",
        "\n",
        "    # 5) Scenario B: full-history schedule\n",
        "    sched_full = build_trade_schedule(det_full, start_date=None, end_date=None)\n",
        "\n",
        "    # 6) Performance bar check\n",
        "    gate = pd.DataFrame([{\n",
        "        \"Target_CAGR%\": 10.0,\n",
        "        \"Target_R_over_MDD\": 3.0,\n",
        "        \"Achieved_CAGR%\": float(summ_full.loc[0, \"CAGR%\"]),\n",
        "        \"Achieved_R_over_MDD\": summ_full.loc[0, \"R_over_MDD\"],\n",
        "        \"Pass?\": (float(summ_full.loc[0, \"CAGR%\"])>=10.0) and ( (summ_full.loc[0, \"R_over_MDD\"]==\"∞\") or (float(summ_full.loc[0, \"R_over_MDD\"])>=3.0) )\n",
        "    }])\n",
        "\n",
        "    # 7) Write Excel\n",
        "    with pd.ExcelWriter(outfile, engine=\"openpyxl\") as ew:\n",
        "        # Parameters sheet\n",
        "        meta = pd.Series({\n",
        "            \"PREFERRED_MODE\": PREFERRED_MODE,\n",
        "            \"ALLOW_FALLBACK_TO_ETF\": ALLOW_FALLBACK_TO_ETF,\n",
        "            \"START\": START, \"END\": END, \"TRADING_DAYS\": TRADING_DAYS,\n",
        "            \"LOOKBACK_YEARS\": LOOKBACK_YEARS, \"MA_LONG\": MA_LONG,\n",
        "            \"EVENT_EVAL_HOLD_D\": EVENT_EVAL_HOLD_D, \"MIN_EVENTS\": MIN_EVENTS,\n",
        "            \"KELLY_FRACTION\": KELLY_FRACTION, \"CAP_PER_ASSET_LONG\": CAP_PER_ASSET_LONG,\n",
        "            \"TOPK_PER_DAY\": TOPK_PER_DAY,\n",
        "            \"TARGET_DAILY_VOL\": TARGET_DAILY_VOL, \"VOL_LOOKBACK_D\": VOL_LOOKBACK_D,\n",
        "            \"VOL_REBAL_FREQ\": VOL_REBAL_FREQ, \"GROSS_LEV_MAX\": GROSS_LEV_MAX,\n",
        "            \"STOP_SIGMA\": STOP_SIGMA, \"TAKE_SIGMA\": TAKE_SIGMA,\n",
        "            \"ENTRY_DD_STOP_ON\": ENTRY_DD_STOP_ON, \"ENTRY_DD_STOP_PCT\": ENTRY_DD_STOP_PCT,\n",
        "            \"TIME_STOP_D\": TIME_STOP_D,\n",
        "            \"BRAKE_THRESH\": BRAKE_THRESH, \"BRAKE_SCALE\": BRAKE_SCALE,\n",
        "            \"MaxDD_Definition\": \"Per-trade drawdown from entry (simple %); portfolio MaxDD is the minimum across trades on close\",\n",
        "            \"CANONICAL_SYMBOLS_USED\": str(list(prices.columns)),\n",
        "            \"USED_ALIASES\": str(used_map),\n",
        "        }).to_frame(\"value\")\n",
        "        meta.index.name = \"Param\"\n",
        "        meta.to_excel(ew, sheet_name=\"Params\")\n",
        "\n",
        "        summ_full.to_excel(ew, sheet_name=\"Summary_Full\", index=False)\n",
        "        gate.to_excel(ew, sheet_name=\"Gate_Check\", index=False)\n",
        "        det_full.to_excel(ew, sheet_name=\"Detail_Full\")\n",
        "\n",
        "        hilo.to_excel(ew, sheet_name=\"Extrema_5_10_20Y\", index=False)\n",
        "        prob.to_excel(ew, sheet_name=\"Event_Prob_2-5-8\", index=False)\n",
        "        today_tbl.to_excel(ew, sheet_name=\"Today_Signals\", index=False)\n",
        "\n",
        "        summ_a.to_excel(ew, sheet_name=\"Scenario_A_Summary\", index=False)\n",
        "        nav_a.rename(\"NAV_A\").to_frame().to_excel(ew, sheet_name=\"Scenario_A_NAV\")\n",
        "        sched_a.to_excel(ew, sheet_name=\"Scenario_A_Schedule\", index=False)\n",
        "\n",
        "        sched_full.to_excel(ew, sheet_name=\"Schedule_Full\", index=False)\n",
        "\n",
        "    print(\"✅ Report generated:\", outfile)\n",
        "    print(\"- Full-history performance:\\n\", summ_full.to_string(index=False))\n",
        "    print(\"- Scenario A performance:\\n\", summ_a.to_string(index=False))\n",
        "    print(\"- Today's signals (post-TopK):\\n\", today_tbl.head(10).to_string(index=False))\n",
        "\n",
        "# =========================\n",
        "# 6) Main flow (default: Scenario A = last one year)\n",
        "# =========================\n",
        "def run_institutional_report():\n",
        "    print(\"\\n=== Loading asset universe (FULL) ===\")\n",
        "    prices, used = load_prices_robust(CANONICAL_SYMBOLS_FULL, START, END)\n",
        "    print(\"[info] Aliases used:\", used)\n",
        "\n",
        "    print(\"\\n=== Generating institutional report ===\")\n",
        "    export_institutional_report(\n",
        "        prices, used,\n",
        "        scenario_start=None,      # None = last 1y; or specify e.g. \"2025-08-01\"\n",
        "        scenario_end=None,        # None = latest; or specify e.g. \"2025-09-22\"\n",
        "        outfile=\"kelly_institutional_report.xlsx\"\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_institutional_report()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HF91RDJRATxo",
        "outputId": "da343036-efd1-495b-dd65-115d89626875"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Loading asset universe (FULL) ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:yfinance:HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: US_SPX\"}}}\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['US_SPX']: YFTzMissingError('possibly delisted; no timezone found')\n",
            "ERROR:yfinance:HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: US_SPX\"}}}\n",
            "ERROR:yfinance:$US_SPX: possibly delisted; no timezone found\n",
            "[try] US_SPX → US_SPX ... no data\n",
            "[warn] yf.download failed for ES=F: 'str' object is not callable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ok] US_SPX → ES=F (5222 rows)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['US_NASDAQ']: YFTzMissingError('possibly delisted; no timezone found')\n",
            "ERROR:yfinance:$US_NASDAQ: possibly delisted; no timezone found\n",
            "[try] US_NASDAQ → US_NASDAQ ... no data\n",
            "[warn] yf.download failed for NQ=F: 'str' object is not callable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ok] US_NASDAQ → NQ=F (5222 rows)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[warn] yf.download failed for SPY: 'str' object is not callable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ok] SPY → SPY (5214 rows)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[warn] yf.download failed for QQQ: 'str' object is not callable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ok] QQQ → QQQ (5214 rows)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[warn] yf.download failed for FEZ: 'str' object is not callable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ok] FEZ → FEZ (5214 rows)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[warn] yf.download failed for EWJ: 'str' object is not callable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ok] EWJ → EWJ (5214 rows)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[warn] yf.download failed for FXI: 'str' object is not callable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ok] FXI → FXI (5214 rows)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[warn] yf.download failed for GLD: 'str' object is not callable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ok] GLD → GLD (5214 rows)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[warn] yf.download failed for SLV: 'str' object is not callable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ok] SLV → SLV (4882 rows)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[warn] yf.download failed for AAPL: 'str' object is not callable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ok] AAPL → AAPL (5214 rows)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[warn] yf.download failed for TSLA: 'str' object is not callable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ok] TSLA → TSLA (3833 rows)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[warn] yf.download failed for MAR: 'str' object is not callable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ok] MAR → MAR (5214 rows)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[warn] yf.download failed for BABA: 'str' object is not callable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ok] BABA → BABA (2769 rows)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[warn] yf.download failed for FSLR: 'str' object is not callable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ok] FSLR → FSLR (4740 rows)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[warn] yf.download failed for SBUX: 'str' object is not callable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ok] SBUX → SBUX (5214 rows)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[warn] yf.download failed for PLTR: 'str' object is not callable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ok] PLTR → PLTR (1251 rows)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[warn] yf.download failed for NVDA: 'str' object is not callable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ok] NVDA → NVDA (5214 rows)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[warn] yf.download failed for 0700.HK: 'str' object is not callable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ok] 700HK → 0700.HK (5112 rows)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[warn] yf.download failed for 0027.HK: 'str' object is not callable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ok] 27HK → 0027.HK (5112 rows)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[warn] yf.download failed for 0883.HK: 'str' object is not callable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ok] 883HK → 0883.HK (5112 rows)\n",
            "[info] Aliases used: {'US_SPX': 'ES=F', 'US_NASDAQ': 'NQ=F', 'SPY': 'SPY', 'QQQ': 'QQQ', 'FEZ': 'FEZ', 'EWJ': 'EWJ', 'FXI': 'FXI', 'GLD': 'GLD', 'SLV': 'SLV', 'AAPL': 'AAPL', 'TSLA': 'TSLA', 'MAR': 'MAR', 'BABA': 'BABA', 'FSLR': 'FSLR', 'SBUX': 'SBUX', 'PLTR': 'PLTR', 'NVDA': 'NVDA', '700HK': '0700.HK', '27HK': '0027.HK', '883HK': '0883.HK'}\n",
            "\n",
            "=== Generating institutional report ===\n",
            "✅ Report generated: kelly_institutional_report.xlsx\n",
            "- Full-history performance:\n",
            "  CooldownD  TotalReturn%  CAGR%  Ann.Vol%  Sharpe  MaxDD%  R_over_MDD  Calmar\n",
            "         0       3019.54  17.61     13.88   1.238  -12.39      243.62   1.421\n",
            "- Scenario A performance:\n",
            "      Start        End  TotalReturn%  CAGR%  Ann.Vol%  Sharpe  MaxDD%  R_over_MDD  Calmar\n",
            "2024-10-04 2025-09-23          8.94   9.01     12.99   0.729  -12.39        0.72   0.727\n",
            "- Today's signals (post-TopK):\n",
            "  Ticker AliasUsed      Side  Trigger(>=th)  Threshold  GateOK  TrendOK  Kelly_raw  k_used_raw  SuggestedWeight Decision\n",
            "    QQQ       QQQ  from_low         1.3535       0.06    True     True     4.4168      0.5000           0.3333 OPEN/ADD\n",
            "   AAPL      AAPL  from_low         1.3095       0.08    True     True     3.0883      0.5000           0.3333 OPEN/ADD\n",
            "0700.HK   0700.HK  from_low         2.4144       0.09    True     True     2.8279      0.5000           0.3333 OPEN/ADD\n",
            "   ES=F      ES=F  from_low         0.9271       0.06    True     True     3.9469      0.5000           0.0000 STAY OUT\n",
            "   NQ=F      NQ=F  from_low         1.3268       0.06    True     True     4.1889      0.5000           0.0000 STAY OUT\n",
            "    SPY       SPY  from_low         1.0414       0.06    True     True     4.4604      0.5000           0.0000 STAY OUT\n",
            "   NVDA      NVDA  from_low        15.0962       0.08    True     True     1.9067      0.3813           0.0000 STAY OUT\n",
            "    FEZ       FEZ from_high         0.0000       0.06   False     True     1.4533      0.0000           0.0000 STAY OUT\n",
            "    EWJ       EWJ from_high         0.0021       0.06    True     True     2.5109      0.0000           0.0000 STAY OUT\n",
            "    FXI       FXI  from_low         1.0967       0.06   False     True     1.2824      0.0000           0.0000 STAY OUT\n"
          ]
        }
      ]
    }
  ]
}